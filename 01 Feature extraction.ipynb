{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Feature extraction</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.12.0\n",
      "Hub version: 0.4.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "In this first part of the project, start by extracting a set of high-level features for each\n",
    "image in the data set. To achieve this, you can use ex. the **Inception v3** or **MobileNet v2**\n",
    "ConvNets which respectively extract 2048 and 1280 high-level features.\n",
    "\n",
    "**Suggestion**: consider storing the extracted high-level features, e.g. in npz files, for\n",
    "quickly reloading them into each of the following notebooks.\n",
    "\n",
    "**Note**: All your models should be trained on the training set, and the fine tuning of your\n",
    "hyperparameters should be validated on the validation set. The final test set should only\n",
    "be used for the final comparison to test the accuracies of your models on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data\n",
    "!unzip -qq swissroads.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only 280 images in the train directory. the sample size is insufficient to train our models.\n",
    "\n",
    "As a solution, we will use, only for training set, data augmentation to generate 5 times additional images from the available ones using keras ImageDataGenerator.\n",
    "\n",
    "Four numpy arrays will be generated and stored in data.npz :\n",
    "    - X_train : a numpy array of shape (1400, 299, 299, 3) which stores the training images.\n",
    "    - X_train_features : a numpy array of shape (1400, 2048) which stores the inception_v3 feature vectors for the training images.\n",
    "    - X_train_1h : The one hot representation of target values\n",
    "    - X_train_1h : Target values\n",
    "\n",
    "Same thing for validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "## initialize tensorflow hun inception_V3 module\n",
    "#module_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'\n",
    "module_url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\n",
    "module = hub.Module(module_url)\n",
    "targetsize = hub.get_expected_image_size(module)\n",
    "\n",
    "## create tensorflow graph\n",
    "img_graph = tf.Graph()\n",
    "with img_graph.as_default():\n",
    "    feature_extractor = hub.Module(module_url)\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, targetsize[0], targetsize[1], 3])\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "    init_op = tf.group([ tf.global_variables_initializer(), tf.tables_initializer() ])\n",
    "img_graph.finalize()\n",
    "\n",
    "## get features from images array X\n",
    "def get_features(X):\n",
    "    with tf.Session(graph=img_graph) as sess:\n",
    "        sess.run(init_op)\n",
    "        features = sess.run(imgs_features, feed_dict={input_imgs: X})\n",
    "    return features\n",
    "\n",
    "## process a generator to extract features from all files in train, validation or test set\n",
    "def process_generator(g,train=False):\n",
    "    np.random.seed(0)\n",
    "    tf.set_random_seed(0)\n",
    "    n=1\n",
    "    if train:\n",
    "       n=4\n",
    "    features = []\n",
    "    data = []\n",
    "    y_1h = []\n",
    "    # for each batch in generator\n",
    "    for i, (X,y) in enumerate(g):\n",
    "        ## break when we have processed all batches.\n",
    "        ## otherwise, generator loop indefinitely\n",
    "        if i+1 > g.__len__()*n:\n",
    "            break\n",
    "        data.append(X)\n",
    "        y_1h.append(y)\n",
    "        features.append(get_features(X))\n",
    "    return np.concatenate(features), np.concatenate(data), np.concatenate(y_1h)\n",
    "# generate data.npz which contains images arrays and features arrays.\n",
    "def save_features_from_images():\n",
    "    np.random.seed(0)\n",
    "    tf.set_random_seed(0)\n",
    "    train_generator1 = ImageDataGenerator(rescale=1/255)\n",
    "    train_generator2 = ImageDataGenerator(rescale=1/255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\n",
    "    valid_generator = ImageDataGenerator(rescale=1/255)\n",
    "    test_generator = ImageDataGenerator(rescale=1/255)\n",
    "    trainset1 = train_generator1.flow_from_directory(os.path.join('data', 'train'), batch_size=140, target_size=targetsize, shuffle=False)\n",
    "    trainset2 = train_generator2.flow_from_directory(os.path.join('data', 'train'), batch_size=140, target_size=targetsize, shuffle=False)\n",
    "    validset = valid_generator.flow_from_directory(os.path.join('data', 'valid'), batch_size=140, target_size=targetsize, shuffle=False)\n",
    "    testset = test_generator.flow_from_directory(os.path.join('data', 'test'), batch_size=140, target_size=targetsize, shuffle=False)\n",
    "    X_test_features, X_test, y_test_1h = process_generator(testset)\n",
    "    print(X_test_features.shape, X_test.shape, y_test_1h.shape)\n",
    "    X_valid_features, X_valid, y_valid_1h = process_generator(validset)\n",
    "    print(X_valid_features.shape, X_valid.shape, y_valid_1h.shape)\n",
    "    # original train images\n",
    "    X_train_features1, X_train1, y_train_1h1 = process_generator(trainset1)\n",
    "    print(X_train_features1.shape, X_train1.shape, y_train_1h1.shape)\n",
    "    # augmented train images\n",
    "    X_train_features2, X_train2, y_train_1h2 = process_generator(trainset2, True)\n",
    "    print(X_train_features2.shape, X_train2.shape, y_train_1h2.shape)\n",
    "    # cmbine the two sets, and shuffle them\n",
    "    idx = list(range(X_train_features1.shape[0]+X_train_features2.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train_features = np.concatenate([X_train_features1,X_train_features2])[idx]\n",
    "    X_train = np.concatenate([X_train1,X_train2])[idx]\n",
    "    y_train_1h = np.concatenate([y_train_1h1,y_train_1h2])[idx]\n",
    "    np.savez('data.npz', X_train=X_train, X_train_features=X_train_features, y_train_1h=y_train_1h, y_train=np.argmax(y_train_1h, axis=1),\n",
    "                     X_valid=X_valid, X_valid_features=X_valid_features, y_valid_1h=y_valid_1h, y_valid=np.argmax(y_valid_1h, axis=1),\n",
    "                     X_test=X_test, X_test_features=X_test_features, y_test_1h=y_test_1h, y_test=np.argmax(y_test_1h, axis=1),\n",
    "                     class_indices=list(trainset1.class_indices.keys()), \n",
    "                     train_filenames=trainset1.filenames, valid_filenames=validset.filenames, test_filenames=testset.filenames\n",
    "                    )\n",
    "## load data from data.npz\n",
    "def load_data():\n",
    "    with np.load('data.npz', allow_pickle=True) as npz_file:\n",
    "        X_train = npz_file['X_train']\n",
    "        X_valid = npz_file['X_valid']\n",
    "        X_test = npz_file['X_test']\n",
    "        X_train_features = npz_file['X_train_features']\n",
    "        X_valid_features = npz_file['X_valid_features']\n",
    "        X_test_features = npz_file['X_test_features']\n",
    "        y_train_1h = npz_file['y_train_1h']\n",
    "        y_valid_1h = npz_file['y_valid_1h']\n",
    "        y_test_1h = npz_file['y_test_1h']\n",
    "        y_train = npz_file['y_train']\n",
    "        y_valid = npz_file['y_valid']\n",
    "        y_test = npz_file['y_test']\n",
    "        class_indices = npz_file['class_indices']\n",
    "        train_filenames = npz_file['train_filenames']\n",
    "        valid_filenames = npz_file['valid_filenames']\n",
    "        test_filenames = npz_file['test_filenames']\n",
    "    return X_train,X_train_features, y_train_1h, y_train, train_filenames, X_valid,X_valid_features, y_valid_1h, y_valid, valid_filenames, X_test, X_test_features, y_test_1h, y_test, test_filenames,class_indices\n",
    "\n",
    "test_results={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load all images from directory, generate features vectors and store all data in data.npz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n",
      "(50, 2048) (50, 299, 299, 3) (50, 6)\n",
      "(139, 2048) (139, 299, 299, 3) (139, 6)\n",
      "(280, 2048) (280, 299, 299, 3) (280, 6)\n",
      "(1120, 2048) (1120, 299, 299, 3) (1120, 6)\n"
     ]
    }
   ],
   "source": [
    "save_features_from_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test data loading here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_train_features, y_train_1h, y_train, train_filenames, X_valid,X_valid_features, y_valid_1h, y_valid, valid_filenames, X_test, X_test_features, y_test_1h, y_test, test_filenames,class_indices = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images [ Train : (1400, 299, 299, 3), Valid : (139, 299, 299, 3), Test (50, 299, 299, 3) ]\n"
     ]
    }
   ],
   "source": [
    "print ('Images [ Train : %s, Valid : %s, Test %s ]'%(X_train.shape, X_valid.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features [ Train : (1400, 2048), Valid : (139, 2048), Test (50, 2048) ]\n"
     ]
    }
   ],
   "source": [
    "print ('Features [ Train : %s, Valid : %s, Test %s ]'%(X_train_features.shape, X_valid_features.shape,X_test_features.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
